{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "# Install Pytorch library\n",
        "!pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "4M1JCEVi48AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google.colab import drive\n",
        "import os, cv2, json\n",
        "from os import getcwd\n",
        "import numpy as np\n",
        "import typing as T\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.image as mpimg\n",
        "import math\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n"
      ],
      "metadata": {
        "id": "78il3dDGBbh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = \"/content/drive/MyDrive/Your_Folder_Name\"\n",
        "\n",
        "# Change the working directory to the specified path\n",
        "os.chdir(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqqKg7xsOEHN",
        "outputId": "79abc4d7-07cb-4e9d-b011-6dc1700cdf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.path.join(os.getcwd(), 'dataset')\n",
        "\n",
        "model = smp.Unet(\n",
        "            encoder_name    = \"efficientnet-b0\",\n",
        "            encoder_weights = None,\n",
        "            in_channels     = 1,\n",
        "            classes         = 5,\n",
        "        )\n",
        "ckpt_path = os.path.join(folder_path,'training/dump/trained_100Epoch/training_checkpoint.pth')\n",
        "ckpt = torch.load(ckpt_path,map_location=torch.device('cpu'))\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "model.eval()\n",
        "model.to('cpu')"
      ],
      "metadata": {
        "id": "JmaA913T-X6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(pil_image):\n",
        "    # Convert PIL image to NumPy array\n",
        "    numpy_array = np.array(pil_image)\n",
        "    # Check the number of channels\n",
        "    num_channels = numpy_array.shape[2] if len(numpy_array.shape) == 3 else 1\n",
        "\n",
        "    # Convert the image to grayscale if it's not already\n",
        "    if num_channels > 1:\n",
        "        gray_image = cv2.cvtColor(numpy_array, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray_image = numpy_array\n",
        "    img = gray_image\n",
        "\n",
        "    IMGSZ = 512\n",
        "    class_names = [\"FP\", \"FPD\", \"ASH\", \"bf\"]\n",
        "    # Augment an image\n",
        "    tensor_image = A.Compose(\n",
        "        [\n",
        "            A.Resize(IMGSZ, IMGSZ, interpolation=cv2.INTER_NEAREST, always_apply=False, p=1),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )(image=img)['image']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = torch.softmax(model(tensor_image.to('cpu').unsqueeze(0).float()).squeeze(0), dim=0)\n",
        "    preds = (preds > 0.5).cpu().numpy()\n",
        "\n",
        "    def get_class_colors(classes):\n",
        "        colors = {\n",
        "            'FP': [128, 0, 128],  # Purple for class 1\n",
        "            \"FPD\": [0, 255, 255],  # Cyan for class 2\n",
        "            \"ASH\": [0, 128, 0],  # Green for class 3\n",
        "            \"bf\": [255, 0, 0],  # Red for class 4\n",
        "        }\n",
        "        return colors\n",
        "\n",
        "    colors = get_class_colors(class_names)\n",
        "\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    rgb = A.Compose(\n",
        "        [\n",
        "            A.Resize(IMGSZ, IMGSZ, interpolation=cv2.INTER_NEAREST, always_apply=True, p=1),\n",
        "        ],\n",
        "    )(image=rgb)['image']\n",
        "\n",
        "    for ch in range(3):\n",
        "        for idx, cls_name in enumerate(class_names):\n",
        "            rgb[:, :, ch][preds[idx + 1] != 0] = colors[cls_name][ch]\n",
        "\n",
        "    # Draw arrow from the center of FP towards FPD if FPD is present\n",
        "    if np.max(preds[2]) != 0:\n",
        "        cords_FP = np.where(preds[1] == 1)\n",
        "        cy_fp, cx_fp = int(np.mean(cords_FP[0])), int(np.mean(cords_FP[1]))\n",
        "\n",
        "        cords_FPD = np.where(preds[2] == 1)\n",
        "        cy_fpd, cx_fpd = int(np.mean(cords_FPD[0])), int(np.mean(cords_FPD[1]))\n",
        "\n",
        "        # Calculate the vector from the center of FP to the center of FPD\n",
        "        vector_fp_fpd = np.array([cx_fpd - cx_fp, cy_fpd - cy_fp])\n",
        "\n",
        "        # Scale the vector to make the arrow longer (e.g., multiplying by 2)\n",
        "        scaled_vector = 1.1 * vector_fp_fpd\n",
        "\n",
        "        # Calculate the endpoint of the arrow after scaling\n",
        "        endpoint = (cx_fp + scaled_vector[0], cy_fp + scaled_vector[1])\n",
        "\n",
        "        # Draw a small circle at the beginning of the arrow\n",
        "        cv2.circle(rgb, (cx_fp, cy_fp), radius=10, color=[0, 0, 255])  # Blue color for the circle\n",
        "\n",
        "        # Draw the arrow\n",
        "        arrow_color = [0, 0, 255]  # Blue color for the arrow\n",
        "        rgb = cv2.arrowedLine(rgb, (cx_fp, cy_fp), (int(endpoint[0]), int(endpoint[1])), arrow_color, thickness=2)\n",
        "\n",
        "        # Convert BGR image to RGB\n",
        "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
        "        # Convert NumPy array to PIL Image\n",
        "        out_img = Image.fromarray(rgb)\n",
        "\n",
        "    return out_img\n"
      ],
      "metadata": {
        "id": "JQy3U15y-hed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=process_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    examples=[\n",
        "        os.path.join(dataset_path, 'test/images', 'Fadul 5-1 3DVM.png'),\n",
        "        os.path.join(dataset_path, 'test/images', 'Fadul 5-2 3DVM.png'),\n",
        "        os.path.join(dataset_path, 'test/images', 'Fadul 6-1 3DVM.png'),\n",
        "        os.path.join(dataset_path, 'test/images', 'Fadul S 3DVM.png'),\n",
        "    ],\n",
        "    live=True,\n",
        ")\n",
        "\n",
        "# Launch the Gradio Interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "z6Z9cP42-5WW",
        "outputId": "f7af43b7-8d6d-463c-bf58-04b51e86c8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7f4a10c5ec920fa79e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7f4a10c5ec920fa79e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}